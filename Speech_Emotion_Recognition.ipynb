{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LteACs3AYVW0"
      },
      "source": [
        "# **Environment Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpsHAPPKYZ-U",
        "outputId": "564ab651-c3a6-4c68-96ed-0d8bcf454b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.1\n",
            "time: 647 µs (started: 2022-09-27 10:46:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZaP-J97HYe7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cacb6753-89c2-4bf1-f6e0-030c51974360"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.34 s (started: 2022-09-27 10:46:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import re\n",
        "import pandas as pd\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63HkKVKj06RE"
      },
      "source": [
        "# **Import Dataset from Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jVxtJd20zvz",
        "outputId": "a80ac2d7-6454-4c5d-b0a1-d41d9693a5b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 657 ms (started: 2022-09-27 10:46:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!mkdir /root/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json /root/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download RAVDESS**"
      ],
      "metadata": {
        "id": "As-ORnO4bBsV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8SBEB0a1N2_",
        "outputId": "c2010aa9-622d-414a-9f2e-37a157bb265e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ravdess-emotional-speech-audio.zip to /content/dataset\n",
            " 99% 424M/429M [00:05<00:00, 83.1MB/s]\n",
            "100% 429M/429M [00:05<00:00, 86.5MB/s]\n",
            "time: 6.05 s (started: 2022-09-27 10:46:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download uwrfkaggler/ravdess-emotional-speech-audio -p /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download CREMA-D**"
      ],
      "metadata": {
        "id": "h_v4UDWya48s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxcXsx06t8TP",
        "outputId": "a2232a2d-c8f5-4e83-9e04-d8aa3f951ea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cremad.zip to /content/dataset\n",
            " 98% 444M/451M [00:03<00:00, 144MB/s]\n",
            "100% 451M/451M [00:03<00:00, 128MB/s]\n",
            "time: 4.76 s (started: 2022-09-27 10:46:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download ejlok1/cremad -p /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download TESS**"
      ],
      "metadata": {
        "id": "2QdVa9l0a8Ho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgtJuqb0B8oS",
        "outputId": "0512aa6b-57f7-47fe-f786-d1f1815acf77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading toronto-emotional-speech-set-tess.zip to /content/dataset\n",
            " 99% 425M/428M [00:03<00:00, 127MB/s]\n",
            "100% 428M/428M [00:03<00:00, 127MB/s]\n",
            "time: 4.53 s (started: 2022-09-27 10:47:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download ejlok1/toronto-emotional-speech-set-tess -p /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download SAVEE**"
      ],
      "metadata": {
        "id": "rsow60xVa9w1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhQ3tnDNB-g3",
        "outputId": "287f3d9c-f5e0-4058-861c-2730071bfec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading savee-database.zip to /content/dataset\n",
            " 97% 208M/215M [00:01<00:00, 149MB/s]\n",
            "100% 215M/215M [00:01<00:00, 148MB/s]\n",
            "time: 2.29 s (started: 2022-09-27 10:47:07 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download barelydedicated/savee-database -p /content/dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract RAVDESS**"
      ],
      "metadata": {
        "id": "e1VHtmuDbFX-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm9sOK-Z1-mQ",
        "outputId": "b6813b9d-4cb1-4a3a-f5d9-d0cb6deb338d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.1 s (started: 2022-09-27 10:47:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "with zipfile.ZipFile(\"/content/dataset/ravdess-emotional-speech-audio.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/dataset/ravdess\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract CREMA-D**"
      ],
      "metadata": {
        "id": "Bxcn58hlbHpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8kEpgQlGLSn",
        "outputId": "2013094c-ad6e-4ef0-94c6-e99608f6720f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.53 s (started: 2022-09-27 10:47:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "with zipfile.ZipFile(\"/content/dataset/cremad.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/dataset/cremad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract SAVEE**"
      ],
      "metadata": {
        "id": "HZtrxLyNbI5C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfi5tYhgCImu",
        "outputId": "792cad5a-b813-4599-aadf-c8f9c8033272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.78 s (started: 2022-09-27 10:47:29 +00:00)\n"
          ]
        }
      ],
      "source": [
        "with zipfile.ZipFile(\"/content/dataset/savee-database.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/dataset/savee\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract TESS**"
      ],
      "metadata": {
        "id": "ByAfm6N5bKts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(\"/content/dataset/toronto-emotional-speech-set-tess.zip\",\"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"/content/dataset/tess\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXc5Vo0ebEuc",
        "outputId": "35038601-2cbf-4117-8deb-a5731cd9a73b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.82 s (started: 2022-09-27 10:47:32 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d16EGVU3qhU",
        "outputId": "086db6a7-013c-43e0-f8ac-405cef5a8ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 760 ms (started: 2022-09-27 10:47:40 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!rm -r /content/dataset/ravdess-emotional-speech-audio.zip\n",
        "!rm -r /content/dataset/cremad.zip\n",
        "!rm -r /content/dataset/toronto-emotional-speech-set-tess.zip\n",
        "!rm -r /content/dataset/savee-database.zip\n",
        "!rm -r /content/dataset/ravdess/audio_speech_actors_01-24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvjyS0O146ov",
        "outputId": "950a2a96-ced3-401e-8ea8-20c0e2d36d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.17 s (started: 2022-09-27 10:47:41 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/converted_images\n",
        "!mkdir /content/converted_images/neutral\n",
        "!mkdir /content/converted_images/calm\n",
        "!mkdir /content/converted_images/happy\n",
        "!mkdir /content/converted_images/sad\n",
        "!mkdir /content/converted_images/angry\n",
        "!mkdir /content/converted_images/fearful\n",
        "!mkdir /content/converted_images/disgust\n",
        "!mkdir /content/converted_images/surprised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bPIzHXn2eQb"
      },
      "source": [
        "# **Data Extraction and Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DOMQIbwP0we"
      },
      "source": [
        "**CREMA-D Sorting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8RjecdGvm2v",
        "outputId": "76c23a85-a2a2-4a87-ac99-a7d180a6604e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.86 ms (started: 2022-09-27 10:47:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def get_label_cremad(file):\n",
        "  labels = [\"ANG\",\"DIS\",\"FEA\",\"HAP\",\"NEU\",\"SAD\"]\n",
        "  for label in labels:\n",
        "    if label in file:\n",
        "      return label\n",
        "\n",
        "  return None\n",
        "\n",
        "def sort_cremad(path,dest):\n",
        "  labels = {\"ANG\":os.path.join(dest,\"angry\"),\n",
        "            \"DIS\":os.path.join(dest,\"disgust\"),\n",
        "            \"FEA\":os.path.join(dest,\"fearful\"),\n",
        "            \"HAP\":os.path.join(dest,\"happy\"),\n",
        "            \"NEU\":os.path.join(dest,\"neutral\"),\n",
        "            \"SAD\":os.path.join(dest,\"sad\")}\n",
        "  images = [file.path for file in os.scandir(path) if \".wav\" in file.path]\n",
        "  for image in images:\n",
        "    image_label = get_label_cremad(image)\n",
        "    shutil.move(image,os.path.join(dest,labels[image_label]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kExbymHg4L8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5b3a6f-b93c-4ace-fb3d-88ac7edf3980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 358 ms (started: 2022-09-27 10:47:42 +00:00)\n"
          ]
        }
      ],
      "source": [
        "sort_cremad(\"/content/dataset/cremad/AudioWAV\",\"/content/converted_images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0dBU0MlP6V1"
      },
      "source": [
        "**RAVDESS Sorting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc45V5nG0k5R",
        "outputId": "cff5e071-6342-486f-b27e-d83af9e1ed7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.79 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def sort_ravdess(path,dest):\n",
        "  labels = [\"neutral\",\"calm\",\"happy\",\"sad\",\"angry\",\"fearful\",\"disgust\",\"surprised\"]\n",
        "  dirs = [file.path for file in os.scandir(path) if file.is_dir()]\n",
        "  for dir in dirs:\n",
        "    files = [file for file in os.scandir(dir) if \".wav\" in file.path]\n",
        "    for file in files:\n",
        "      dest_path = os.path.join(dest,labels[int(file.name[7])-1])\n",
        "      shutil.move(file.path,dest_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSKj1Uwh3hvn",
        "outputId": "c14884b9-8415-464a-bd7f-b3d2083f6c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 72.4 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "sort_ravdess(\"/content/dataset/ravdess\",\"/content/converted_images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qllrdi8YP83Q"
      },
      "source": [
        "**SAVEE Sorting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1JY_3NniDqQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a78b485-b247-4650-e44a-2d2ae2d54da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.77 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def get_label_savee(file):\n",
        "  labels = [\"a\",\"d\",\"f\",\"h\",\"n\",\"sa\",\"su\"]\n",
        "  for label in labels:\n",
        "    pattern = \"^\"+label\n",
        "    if re.search(pattern,file) != None:\n",
        "      return label\n",
        "\n",
        "  return None\n",
        "\n",
        "def sort_savee(path,dest):\n",
        "  counter = 0\n",
        "  labels = {\"a\":os.path.join(dest,\"angry\"),\n",
        "            \"d\":os.path.join(dest,\"disgust\"),\n",
        "            \"f\":os.path.join(dest,\"fearful\"),\n",
        "            \"h\":os.path.join(dest,\"happy\"),\n",
        "            \"n\":os.path.join(dest,\"neutral\"),\n",
        "            \"sa\":os.path.join(dest,\"sad\"),\n",
        "            \"su\":os.path.join(dest,\"surprised\")}\n",
        "\n",
        "  dirs = [file.path for file in os.scandir(path) if file.is_dir()]\n",
        "  for dir in dirs:\n",
        "    files = [file for file in os.scandir(dir) if \".wav\" in file.path]\n",
        "    for file in files:\n",
        "        new_file_name = os.path.join(dest,labels[get_label_savee(file.name)])\n",
        "        new_file_name = os.path.join(new_file_name,(str(counter) + \".wav\"))\n",
        "        shutil.move(file.path,new_file_name)\n",
        "        counter+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "H2o7PzHBFAyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7399d64f-2b5b-4dc9-babb-aa33e0e37600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 34.9 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "sort_savee(\"/content/dataset/savee/AudioData\",\"/content/converted_images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ixcRNCeP_b-"
      },
      "source": [
        "**TESS Sorting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0ImHaxBHPlq",
        "outputId": "28d78153-4d81-4c11-976a-e332800989b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.59 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def get_label_tess(file):\n",
        "  labels = [\"angry\",\"disgust\",\"fear\",\"happy\",\"neutral\",\"ps\",\"sad\"]\n",
        "  for label in labels:\n",
        "    if label in file:\n",
        "      return label\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def sort_tess(path,dest):\n",
        "  labels = {\"angry\":os.path.join(dest,\"angry\"),\n",
        "            \"disgust\":os.path.join(dest,\"disgust\"),\n",
        "            \"fear\":os.path.join(dest,\"fearful\"),\n",
        "            \"happy\":os.path.join(dest,\"happy\"),\n",
        "            \"neutral\":os.path.join(dest,\"neutral\"),\n",
        "            \"ps\":os.path.join(dest,\"surprised\"),\n",
        "            \"sad\":os.path.join(dest,\"sad\")}\n",
        "  dirs = [file.path for file in os.scandir(path) if file.is_dir()]\n",
        "  for dir in dirs:\n",
        "    files = [file for file in os.scandir(dir) if \".wav\" in file.path]\n",
        "    for file in files:\n",
        "      shutil.move(file.path,os.path.join(dest,labels[get_label_tess(file.name)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvuno-p_Io0k",
        "outputId": "6508836a-f4a9-4e11-8826-81e8b8d70d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 137 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ],
      "source": [
        "sort_tess(\"/content/dataset/tess/TESS Toronto emotional speech set data\",\"/content/converted_images\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**WAV to MFCCs**"
      ],
      "metadata": {
        "id": "iK2_1VJBc_Uc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_files(path):\n",
        "  counter = 0\n",
        "  dirs = [dir.path for dir in os.scandir(path) if dir.is_dir()]\n",
        "  for dir in dirs:\n",
        "    files = [file.path for file in os.scandir(dir) if file.is_file()]\n",
        "    for file in files:\n",
        "      counter+=1\n",
        "\n",
        "  return counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGI5lnVaxzk0",
        "outputId": "34164e60-087a-45d7-d58d-00c5a90dccb4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.88 ms (started: 2022-09-27 10:47:43 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampling_rate=44100\n",
        "audio_duration=2.5\n",
        "n_mfcc = 25\n",
        "mfcc_length = 216 #depends on input_length\n",
        "num_files = get_num_files(\"/content/converted_images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSFeJFPldCcZ",
        "outputId": "0a21c51c-0297-45ca-ca6f-b2a7ada56a75"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 27.2 ms (started: 2022-09-27 11:03:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_DHELhjqM3BH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee24acf0-31ce-4e72-a14c-1389f57d75f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 4.43 ms (started: 2022-09-26 18:22:47 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def convert_in_dir(dir,sampling_rate,audio_duration,num_files):\n",
        "  input_length = sampling_rate * audio_duration\n",
        "  X = np.empty(shape=(num_files,n_mfcc, mfcc_length, 1))\n",
        "  Y = np.empty(shape=(num_files),dtype=\"object\")\n",
        "  counter = 0\n",
        "  subdirs = [subdir.path for subdir in os.scandir(dir) if subdir.is_dir()]\n",
        "  for subdir in subdirs:\n",
        "    label = subdir.split(\"/\")[-1]\n",
        "    files = [wav.path for wav in os.scandir(subdir) if wav.is_file() and \".wav\" in wav.path]\n",
        "    for wav in files:\n",
        "      data, _ = librosa.load(wav, sr=sampling_rate\n",
        "                               ,res_type=\"kaiser_fast\"\n",
        "                               ,duration=audio_duration\n",
        "                               ,offset=0.5\n",
        "                              )\n",
        "\n",
        "      data = librosa.util.fix_length(data,input_length)\n",
        "      MFCC = librosa.feature.mfcc(data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
        "      MFCC = np.expand_dims(MFCC, axis=-1)\n",
        "      X[counter,] = MFCC\n",
        "      Y[counter] = label\n",
        "      counter+=1\n",
        "      print(counter)\n",
        "\n",
        "  return X,Y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = convert_in_dir(\"/content/converted_images\", sampling_rate,audio_duration,num_files)"
      ],
      "metadata": {
        "id": "9C55uVPpmNne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train and Test Set building**"
      ],
      "metadata": {
        "id": "lq1HNYmVdJix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TIVXTyK0lvI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfbf964-7f3b-4283-b92c-a908f6a0fd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 174 ms (started: 2022-09-26 18:32:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x,test_x,train_y,test_y = train_test_split(X,Y,shuffle=True,test_size=0.2,stratify=Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1_M-U7VARs8",
        "outputId": "08826f97-58b6-41bb-ba3e-b55e9b974b03"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['fearful', 'happy', 'sad', 'neutral', 'happy', 'neutral', 'angry',\n",
              "       'angry', 'happy', 'sad'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.12 ms (started: 2022-09-26 18:32:58 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "fUKU6b4kQDRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93de2dab-aed6-4d43-9808-3922bef206bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 8.56 ms (started: 2022-09-26 18:32:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "one_hot = OneHotEncoder()\n",
        "\n",
        "train_y = one_hot.fit_transform(train_y.reshape(-1,1)).toarray()\n",
        "test_y = one_hot.fit_transform(test_y.reshape(-1,1)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rifwd8t1b28h",
        "outputId": "37b91b6b-d936-4ef3-961a-68d74da55df3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9729, 25, 216, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.93 ms (started: 2022-09-26 18:32:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "train_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiZfM_uQh4Rx",
        "outputId": "be0df0eb-5119-480b-9a7b-52deec940945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 564 ms (started: 2022-09-26 18:32:58 +00:00)\n"
          ]
        }
      ],
      "source": [
        "mean = np.mean(train_x, axis=0)\n",
        "std = np.std(train_x, axis=0)\n",
        "\n",
        "train_x = (train_x - mean)/std\n",
        "test_x = (test_x - mean)/std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0O5eXnlbXzd"
      },
      "source": [
        "# **Training and Testing with 2D CNN**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(n_mfcc,mfcc_length,1)))\n",
        "\n",
        "model.add(tf.keras.layers.Convolution2D(32, 3, padding=\"same\",activation=\"relu\"))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Convolution2D(32, 3, padding=\"same\",activation=\"relu\"))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Convolution2D(32, 3, padding=\"same\",activation=\"relu\"))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Convolution2D(32, 3, padding=\"same\",activation=\"relu\"))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPool2D())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(64,activation=\"relu\"))\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.2))\n",
        "model.add(tf.keras.layers.Dense(8,activation=\"softmax\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfgOZbhoXj0v",
        "outputId": "52f3e652-7735-47fd-aa51-0fac9aa27af4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 301 ms (started: 2022-09-27 11:03:22 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0jh9OC9bZsy"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cnaXHf5cBOm",
        "outputId": "fcea98dc-8327-4e92-f1d8-4c87e0edd206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 13.5 ms (started: 2022-09-26 18:58:15 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOZq5Sfx_jeG",
        "outputId": "f879f12b-2f08-4b68-f62a-68ca6addcd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 863 µs (started: 2022-09-26 18:58:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "lr_plateau = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\",patience=8,verbose=1,factor=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2u-M_evhJYe",
        "outputId": "8f732e63-c4a5-4786-f087-1c29911555a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 11.7 ms (started: 2022-09-26 18:58:17 +00:00)\n"
          ]
        }
      ],
      "source": [
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/model_checkpoints\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yfo-yTwmcK-a"
      },
      "outputs": [],
      "source": [
        "model.fit(train_x,train_y,validation_data=(test_x,test_y),epochs=100,callbacks=[lr_plateau,model_checkpoint])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}